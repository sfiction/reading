## 2 感知机

## 4 朴素贝叶斯法

确实很朴素，只是对假设特征分布相互独立，然后应用贝叶斯公式而已。

### 4.2 朴素贝叶斯法的参数估计

极大似然估计

为了避免出现概率值为 0 的情况，采用贝叶斯估计，给每个频数增加 $\lambda$。$\lambda$ 为 0 时即为极大似然估计，为 1 时一般称拉普拉斯平滑。

## 5 决策树

### 5.2 特征选择

信息熵

给定随机变量 X 和 Y，条件熵 $H(Y|X)$ 是指 X 给定条件下 Y 的条件概率分布的熵对 X 的数学期望。即 $H(Y|X)=\sum_{i=1}^{n}{p_i H(Y|X=x_i)}$

信息增益：给定条件 X 下 Y 的条件熵与 Y 的信息熵之差

对一个数据集而言，使用信息增益作为特征划分效果的评判标准，会导致取值数多的特征占据优势。可以用信息增益比避免这个问题。

### 5.3 决策树的生成

- ID3, 将单类别/无可用特征/最大信息增益低于阈值的结点设为叶节点，否则用最大信息增益的特征划分集合，递归处理
  - 只有生成过程，容易过拟合
- C4.5, 与 ID3 类似，只是改用信息增益比选择用于划分的特征

### 5.4 决策树的剪枝

给定一个整体的损失函数，根据删减前后损失函数的变化决定是否要将某个结点的儿子全部删去。

一般采用结点个数作为正则化项。

### 5.5 CART 算法

